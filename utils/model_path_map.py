LOCAL_MODEL_PATHS = {
    # Task 1-3
    "Llama-3-8B-Instruct": "/opt/data/private/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/8afb486c1db24fe5011ec46dfbe5b5dccdb575c2",
    "Llama-3.0-8B-Instruct": "/opt/data/private/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/8afb486c1db24fe5011ec46dfbe5b5dccdb575c2",
    "Llama-3.1-8B-Instruct": "/opt/data/private/huggingface/hub/models--meta-llama--Llama-3.1-8B-Instruct/snapshots/0e9e39f249a16976918f6564b8830bc894c89659",
    "Llama-3.2-1B-Instruct": "",
    "Llama-3.2-3B-Instruct": "",
    "Llama-3.2-11B-Vision-Instruct": "",
    "Llama-3.3-70B-Instruct": "/opt/data/private/huggingface/hub/models--meta-llama--Llama-3.3-70B-Instruct/snapshots/6f6073b423013f6a7d4d9f39144961bfbfbc386b",
    "Llama-4-Scout-17B-16E-Instruct": "/opt/data/private/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/snapshots/92f3b1597a195b523d8d9e5700e57e4fbb8f20d3",
    "Qwen2.5-7B-Instruct": "/opt/data/private/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28",
    "Qwen2.5-14B-Instruct": "/opt/data/private/huggingface/hub/models--Qwen--Qwen2.5-14B-Instruct/snapshots/cf98f3b3bbb457ad9e2bb7baf9a0125b6b88caa8",
    "Qwen3-1.7B": "",
    "Qwen3-4B": "",
    "Qwen3-4B-Instruct-2507": "",
    "Qwen3-8B": "",
    "Qwen3-14B": "",
    "gemma-2-9b-it": "/opt/data/private/huggingface/hub/models--google--gemma-2-9b-it/snapshots/11c9b309abf73637e4b6f9a3fa1e92e615547819",
    "gemma-3-27b-it": "/opt/data/private/huggingface/hub/models--google--gemma-3-27b-it/snapshots/dfb98f29ff907e391ceed2be3834ca071ea260f1",
    "Llama-3.1-8B": "/opt/data/private/huggingface/hub/models--meta-llama--Llama-3.1-8B/snapshots/d04e592bb4f6aa9cfee91e2e20afa771667e1d4b",
    "Llama-3.2-11B-Vision": "/opt/data/private/huggingface/hub/models--meta-llama--Llama-3.2-11B-Vision/snapshots/3f2e93603aaa5dd142f27d34b06dfa2b6e97b8be",
    "DeepSeek-R1-Distill-Llama-8B": "/opt/data/private/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Llama-8B/snapshots/6a6f4aa4197940add57724a7707d069478df56b1",
    # Task 4
    "Llama-4-Scout-17B-16E-Instruct": "/opt/data/private/huggingface/hub/models--meta-llama--Llama-4-Scout-17B-16E-Instruct/snapshots/92f3b1597a195b523d8d9e5700e57e4fbb8f20d3",
    "Qwen2.5-VL-7B-Instruct": "/opt/data/private/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5",
    "Qwen2.5-VL-32B-Instruct": "/opt/data/private/huggingface/hub/models--Qwen--Qwen2.5-VL-32B-Instruct/snapshots/7cfb30d71a1f4f49a57592323337a4a4727301da",
} 

# LOCAL_MODEL_PATHS = {
#     # Task 1-3
#     "Llama-3.1-8B-Instruct": "huggingface/meta-llama/Llama-3.1-8B-Instruct",
#     "Llama-3.2-1B-Instruct": "huggingface/meta-llama/Llama-3.2-1B-Instruct",
#     "Llama-3.2-3B-Instruct": "huggingface/meta-llama/Llama-3.2-3B-Instruct",
#     "Llama-3.2-11B-Vision-Instruct": "huggingface/meta-llama/Llama-3.2-11B-Vision-Instruct",
#     "Llama-3.3-70B-Instruct": "huggingface/meta-llama/Llama-3.3-70B-Instruct",
#     "Llama-4-Scout-17B-16E-Instruct": "huggingface/meta-llama/Llama-4-Scout-17B-16E-Instruct",
#     "Qwen2.5-7B-Instruct": "huggingface/Qwen/Qwen2.5-7B-Instruct",
#     "Qwen2.5-14B-Instruct": "huggingface/Qwen/Qwen2.5-14B-Instruct",
#     "Qwen3-1.7B": "huggingface/Qwen/Qwen3-1.7B",
#     "Qwen3-4B": "huggingface/Qwen/Qwen3-4B",
#     "Qwen3-4B-Instruct-2507": "huggingface/Qwen/Qwen3-4B-Instruct-2507",
#     "Qwen3-8B": "huggingface/Qwen/Qwen3-8B",
#     "Qwen3-14B": "huggingface/Qwen/Qwen3-14B",
#     # Task 4
#     "Llama-4-Scout-17B-16E-Instruct": "huggingface/meta-llama/Llama-4-Scout-17B-16E-Instruct",
#     "Qwen2.5-VL-7B-Instruct": "huggingface/Qwen/Qwen2.5-VL-7B-Instruct",
#     "Qwen2.5-VL-32B-Instruct": "huggingface/Qwen/Qwen2.5-VL-32B-Instruct",
# } 